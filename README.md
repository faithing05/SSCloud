# **SSCloud - Semantic Segmentation Cloud**

**SSCloud** — это проект, предназначенный для работы с семантической сегментацией изображений. Он включает в себя инструменты для полуавтоматической разметки данных с использованием [CVAT](https://github.com/cvat-ai/cvat) и последующего обучения нейросетевой архитектуры [Unet](https://github.com/milesial/Pytorch-UNet) на подготовленном датасете.

Этот репозиторий содержит все необходимые инструкции и скрипты для развертывания окружения, подготовки данных и запуска процессов обучения и инференса (применения модели).

## **Часть 1: Настройка локального сервера CVAT**

[CVAT (Computer Vision Annotation Tool)](https://github.com/cvat-ai/cvat) — это мощный инструмент для разметки изображений и видео. Следующие шаги помогут вам развернуть его локально с помощью Docker.

### **1. Клонирование репозитория CVAT**
Если у вас еще нет локальной копии репозитория CVAT, выполните следующую команду в терминале:
```bash
git clone https://github.com/cvat-ai/cvat
```

### **2. Переход в директорию проекта**
```bash
cd cvat
```

### **3. Сборка и запуск контейнеров**
Эта команда скачает последние образы CVAT и запустит все необходимые сервисы в фоновом режиме (флаг `-d`).
```bash
docker-compose up -d
```

### **4. Проверка статуса сервисов**
Подождите несколько минут, пока все компоненты запустятся. Убедиться, что все работает корректно, можно с помощью команды:
```bash
docker-compose ps
```

### **5. Создание суперпользователя**
Для доступа к интерфейсу CVAT необходимо создать учетную запись администратора. Сначала зайдите внутрь контейнера:
```bash
docker exec -it cvat_server bash
```
Затем, находясь внутри контейнера, выполните команду для создания пользователя и следуйте инструкциям в терминале:
```bash
python manage.py createsuperuser
```
После создания пользователя выйдите из контейнера:
```bash
exit
```

### **6. Доступ к веб-интерфейсу**
Чтобы узнать адрес, по которому доступен веб-интерфейс (обычно это `http://localhost:8080/`), и посмотреть логи сервиса, выполните:
```bash
docker logs cvat_server -f
```
Откройте указанный адрес в браузере. Для остановки просмотра логов нажмите `CTRL+C`.

### **7. Остановка и удаление контейнеров CVAT**
Когда вы закончите работу с CVAT, остановить все сервисы и удалить контейнеры можно командой:
```bash
docker-compose down
```

## **Часть 2: Запуск веб-сервиса для полуавтоматической сегментации (FastAPI + SAM)**

Этот раздел описывает, как запустить интерактивное веб-приложение для разметки панорам с использованием модели Segment Anything (SAM).

### Шаг 1: Подготовка

Перед первым запуском убедитесь, что у вас установлены:
*   **Docker** и **Docker Desktop** (для Windows/Mac).
*   **Драйверы NVIDIA** для вашей видеокарты (если планируете использовать GPU).
*   **NVIDIA Container Toolkit** для поддержки GPU внутри Docker.

Затем необходимо подготовить файлы проекта:
1.  **Скачайте модель Segment Anything**: Загрузите веса модели `vit_h` (файл `sam_vit_h_4b8939.pth`) и поместите его в папку `models/`.
2.  **Подготовьте панорамы**: Убедитесь, что ваши `.jpg` файлы панорам находятся в папке `Vistino20241014_E57/`.

### Шаг 2: Сборка Docker-образа

Этот шаг создает самодостаточный образ вашего приложения со всеми необходимыми библиотеками. Модель SAM будет скопирована внутрь образа.

1.  Откройте терминал (PowerShell, CMD или терминал Linux) в корневой папке проекта `SSCloud`.
2.  Выполните команду:
    ```bash
    docker build -t sscloud-service .
    ```
*   `-t sscloud-service` присваивает образу удобное имя.
*   Точка `.` в конце указывает, что сборка должна происходить в текущей директории.

*Примечание: Первая сборка может занять значительное время, так как Docker будет скачивать базовый образ CUDA и устанавливать PyTorch.*

### Шаг 3: Запуск Docker-контейнера

Эта команда запускает ваше веб-приложение. Важно использовать флаги `-v`, чтобы "пробросить" папки с данными и результатами с вашего компьютера внутрь контейнера.

```powershell
docker run --gpus all -p 8000:8000 ` -v "${PWD}:/workspace/SSCloud" ` keiretsu/sscloud:v1 
```
*   PowerShell понимает переменную `${PWD}` как "текущая рабочая директория"
*   `--gpus all`: предоставляет контейнеру доступ к GPU. Если у вас нет GPU, уберите этот флаг.
*   `-p 8000:8000`: делает приложение, работающее внутри контейнера на порту 8000, доступным на порту 8000 вашего компьютера.
*   `-v ...`: связывает папку на вашем компьютере (слева от `:`) с папкой внутри контейнера (справа от `:`). Это позволяет приложению читать ваши панорамы и сохранять результаты (`CVAT_Workspace`) прямо на ваш компьютер.

После запуска вы увидите в терминале логи загрузки модели и сообщение о том, что сервер запущен на `http://0.0.0.0:8000`.

Эта команда запускает терминал уже в работающем контейнере.
```powershell
docker exec -it 99f9f2b998f2 /bin/bash
```
* `99f9f2b998f2` - CONTAINER ID, узнается через docekr ps

### Шаг 4: Использование интерфейса

1.  Откройте веб-браузер (например, Chrome) и перейдите по адресу:
    **`http://127.0.0.1:8000/index.html`**

2.  Вы увидите простой интерфейс. В поле "Имя файла панорамы" введите точное имя файла, который находится в папке `Vistino20241014_E57` (например, `3_normals.jpg`).

3.  Нажмите кнопку **"Начать обработку"**. В терминале вы увидите лог процесса генерации масок. Это может занять несколько минут.

4.  После завершения на странице появится первая подсвеченная маска и кнопки с классами. Нажимайте на кнопки, чтобы присвоить класс каждой маске, или "Пропустить".

5.  После классификации всех масок результаты будут сохранены в папке `CVAT_Workspace/<имя_панорамы>/`. Вы можете добавить в интерфейс кнопку для вызова эндпоинта, который будет собирать финальный ZIP-архив для CVAT.

## **Часть 3: Обучение и инференс модели Unet**

Этот раздел посвящен обучению архитектуры **Unet** на вашем датасете и последующему применению обученной модели для предсказания масок.

### **Подготовка данных**
Перед обучением необходимо подготовить датасет. Скрипт `convert_labelme.py` обрабатывает ваши панорамы и разметку:
*   Исходные изображения перемещаются в `train/data/imgs`.
*   Маски сегментации преобразуются в нужный формат и перемещаются в `train/data/masks`.

### **Запуск контейнера для Unet**

**Для обучения:**
Эта команда запускает контейнер `milesial/unet`, монтируя вашу папку с данными (`data`) внутрь контейнера.
*   `--shm-size=8g`: увеличивает размер разделяемой памяти, что может быть полезно при работе с большими объемами данных.
```bash
docker run --rm -it --gpus all --shm-size=8g --ulimit memlock=-1 -v "${PWD}/data:/app/data" milesial/unet
```

**Для инференса (применения модели):**
Эта команда также запускает контейнер, но монтирует папки для тестовых данных, вывода и моделей (`checkpoints`).
```bash
docker run --rm -it --gpus all -v "${PWD}:/workspace/unet" milesial/unet
```

### **Работа внутри контейнера**

**Запуск обучения:**
После входа в контейнер, запустите обучение модели.
*   `WANDB_MODE=offline`: отключает логирование в Weights & Biases.
*   `--epochs 50`: количество эпох обучения.
*   `--batch-size 1`: размер батча.
*   `--scale 0.1`: коэффициент масштабирования изображений.
*   `--classes 68`: количество классов сегментации.
```bash
WANDB_MODE=offline python train.py --epochs 50 --batch-size 1 --scale 0.1 --amp --classes 68
```
    
**Запуск инференса:**
Применение обученной модели для предсказания на одном изображении, на определенной эпохе
*   `-m checkpoints/checkpoint_epoch48.pth`: путь к файлу с весами модели.
*   `-i test_input/1_normals.jpg`: входное изображение.
*   `-o test_output/predicted_mask.png`: путь для сохранения результата.
```bash
python predict.py -m checkpoints/checkpoint_epoch48.pth -i test_input/1_normals.jpg -o test_output/predicted_mask.png --scale 0.1 --classes 68
```

Применение обученной модели для предсказания на одном изображении, но на всех эпохах. 
```bash
cd train
```
```bash
python predict_all_epoch.py -i data/test/input/1_normals.jpg
```

**Визуализация результата:**
Для наглядного представления результата работы модели (инференса) используйте этот скрипт:
```powershell
python visualize_prediction.py
```
